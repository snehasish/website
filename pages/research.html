<!DOCTYPE html>
<html lang="en">
<head>
        <title>Research</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <!-- Removed FEED blocks, will add back ONE later -->
        <link href="http://www.snehasish.net/theme/css/bootstrap.css" rel="stylesheet" media="screen">
        <link href="http://www.snehasish.net/theme/css/bootstrap-responsive.min.css" rel="stylesheet" media="screen">
        <link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light+Two' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="http://www.snehasish.net/theme/css/base.css" />
        <link rel="stylesheet" href="http://www.snehasish.net/theme/css/syntax.css" />
        <script src="http://www.snehasish.net/theme/js/jquery-2.0.2.min.js"></script>
        <script src="http://www.snehasish.net/theme/js/bootstrap.min.js"></script>
</head>

<body id="index" class="home">

        <div class="container">

            <div class="row">            
                <div class="span12">
                    <h1 id="site-header"><a href="http://www.snehasish.net">Snehasish</a>
                        <small style="font-size:40%">(pronounced snā-hä-SHēSH)</small></h1>
                </div>
            </div>
            <hr style="margin:0px 0px 10px 0px;"/>
            <div class="row">
                <div class="span12">
                    <ul class="nav nav-pills pull-right">
                    
                    <li  ><a href="http://www.snehasish.net/index.html">Home</a></li>

                            <li><a href="http://www.snehasish.net/category/notes.html">Notes</a></li>

                            <li><a href="http://www.snehasish.net/pages/contact.html">Contact</a></li>
                            <li><a href="http://www.snehasish.net/pages/news.html">News</a></li>
                            <li class="active"><a href="http://www.snehasish.net/pages/research.html">Research</a></li>
                            <li><a href="http://www.snehasish.net/pages/resume.html">Resume</a></li>

                    
                    
                    </ul>
                </div>    
            </div>    
    <h3>FUSION: Design Tradeoffs in Coherence Hierarchies for Accelerators</h3>
<h4>Snehasish Kumar, Arrvindh Shriraman, Naveen Vedula</h4>
<h4>(2015) Proceedings of the 42nd Annual IEEE/ACM International Symposium on Computer Architecture</h4>
<hr />
<h3>DAX : Hardware Accelerator for Collecting Software Data Structures</h3>
<h4>Snehasish Kumar, Naveen Vedula, Arrvindh Shriraman, Vijayalakshmi Srinivasan</h4>
<h4>(2015) Proceedings of the 29th Annual ACM International Conference on Supercomputing</h4>
<p>Recent research has proposed compute accelerators to
address the energy efficiency challenge. While these compute accelerators
specialize and improve the compute efficiency, they have
tended to rely on address-based load/store memory interface that closely
resembles a traditional processor core; in some cases accelerators
even tend to use the core for loads and stores. The address-based
load/store interface is particularly challenging in datacentric applications
that tend to access different software data structures. While
accelerators optimize the compute section, the address-based interface
leads to wasteful instructions and low memory level parallelism
(MLP). We study the benefits of raising the abstraction of the memory
interface to data structures.
We propose DAX (Datastructure Accelerator), a specialized data
fetch state machine that enables compute accelerators to efficiently
access data structure elements in iterative program regions. DAX enables
the compute accelerators to employ data structure based memory
operations and relieves the compute unit from having to generate
addresses for each individual object. DAX exploits knowledge of the
program’s iteration to i) run ahead of the compute units and gather
data objects for the compute unit (i.e., compute unit memory operations
do not encounter cache misses) and ii) throttle the fetch rate
and adaptively tile the dataset based on the locality characteristics
and guarantee cache residency. We demonstrate three types of data
structure accelerators, Vector, Key-Value, and a BTree. We demonstrate
the benefits of DAX on datacentric applications which have
varied computation kernels but access a few regular data structures.
DAX achieves higher energy efficiency by eliminating the data structure
instructions and enabling energy efficient compute accelerators
to efficiently access the data elements. We demonstrate that DAX can
achieve 4.4× the performance improvement of the multicore system
by discovering more parallelism from the data structure.</p>
<hr />
<h3>Protozoa : Adaptive Granularity Cache Coherence</h3>
<h4>Hongzhou Zhao, Arrvindh Shriraman, Snehasish Kumar, Sandhya Dwarkadas</h4>
<h4>(2013) Proceedings of the 40th Annual IEEE/ACM International Symposium on Computer Architecture</h4>
<p>State-of-the-art multiprocessor cache hierarchies propagate the use
of a fixed granularity in the cache organization to the design of the
coherence protocol. Unfortunately, the fixed granularity, generally
chosen to match average spatial locality across a range of applications,
not only results in wasted bandwidth to serve an individual
thread’s access needs, but also results in unnecessary coherence traf-
fic for shared data. The additional bandwidth has a direct impact on
both the scalability of parallel applications and overall energy consumption.
In this paper, we present the design of Protozoa, a family of coherence
protocols that eliminate unnecessary coherence traffic and
match data movement to an application’s spatial locality. Protozoa
continues to maintain metadata at a conventional fixed cache
line granularity while 1) supporting variable read and write caching
granularity so that data transfer matches application spatial granularity,
2) invalidating at the granularity of the write miss request so
that readers to disjoint data can co-exist with writers, and 3) potentially
supporting multiple non-overlapping writers within the cache
line, thereby avoiding the traditional ping-pong effect of both readwrite
and write-write false sharing. Our evaluation demonstrates that
Protozoa consistently reduce miss rate and improve the fraction of
transmitted data that is actually utilized.</p>
<p><a href="http://dl.acm.org/citation.cfm?id=2485969">PDF from ACM DL</a></p>
<hr />
<h3>Amoeba-Cache: Adaptive Blocks for Eliminating Waste in the Memory Hierarchy</h3>
<h4>Snehasish Kumar, Hongzhou Zhao, Arrvindh Shriraman, Eric Matthews, Sandhya Dwarkadas, Lesley Shannon</h4>
<h4>(2012) Proceedings of the 45th Annual IEEE/ACM International Symposium on Microarchitecture</h4>
<p>The fixed geometries of current cache designs do not adapt to the
working set requirements of modern applications, causing significant
inefficiency. The short block lifetimes and moderate spatial locality
exhibited by many applications result in only a few words in the
block being touched prior to eviction. Unused words occupy between
17—80% of a 64K L1 cache and between 1%—79% of a 1MB private
LLC. This effectively shrinks the cache size, increases miss rate, and
wastes on-chip bandwidth. Scaling limitations of wires mean that
unused-word transfers comprise a large fraction (11%) of on-chip
cache hierarchy energy consumption.</p>
<p>We propose Amoeba-Cache, a design that supports a variable number
of cache blocks, each of a different granularity. Amoeba-Cache
employs a novel organization that completely eliminates the tag array,
treating the storage array as uniform and morphable between tags
and data. This enables the cache to harvest space from unused words
in blocks for additional tag storage, thereby supporting a variable
number of tags (and correspondingly, blocks). Amoeba-Cache adjusts
individual cache line granularities according to the spatial locality
in the application. It adapts to the appropriate granularity both for
different data objects in an application as well as for different phases
of access to the same data. Overall, compared to a fixed granularity
cache, the Amoeba-Cache reduces miss rate on average (geometric
mean) by 18% at the L1 level and by 18% at the L2 level and reduces
L1—L2 miss bandwidth by '46%. Correspondingly, Amoeba-Cache
reduces on-chip memory hierarchy energy by as much as 36% (mcf)
and improves performance by as much as 50% (art).</p>
<p><a href="http://dl.acm.org/citation.cfm?id=2457513">PDF from ACM DL</a></p>

            <hr style="margin:30px 0px 0px 0px;"/>
            <div class="row">
                <div class="span12">
                    <footer class="text-center"> Generated by <a href="http://blog.getpelican.com/">pelican</a>. Uses Google <a href="http://www.google.com/fonts/">webfonts</a> and Twitter <a href="http://twitter.github.io/bootstrap/">bootstrap</a>.
                    <br />Copyright &copy; Snehasish Kumar, 2015
                    </footer>
                </div> 
            </div>

        </div>
<script type="text/javascript">
    var disqus_shortname = 'snehasish';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-42112602-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>
</html>